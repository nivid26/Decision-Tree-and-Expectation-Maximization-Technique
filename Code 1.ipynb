{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesmo.metrics import nrmsd\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import impyute as impy\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from chefboost import Chefboost as chef\n",
    "from openpyxl import load_workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42056c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMI(complete_data , df_incomplete_data):      \n",
    "    ######################################Step-1##############################################\n",
    "    #Split DF into DI and DC subsets\n",
    "    DI = df_incomplete_data[df_incomplete_data.isnull().any(axis=1)] #Xmis is the incomplete subset of X\n",
    "    index_list_DI = DI.index\n",
    "    DC = df_incomplete_data.dropna(inplace=False) #Xobs is the complete subset of X\n",
    "    L = 0\n",
    "    \n",
    "    ######################################Step-2############################################## \n",
    "    M = DI.columns.get_indexer(DI.columns[DI.isnull().any()].tolist())  #total no. of attributes in DI having missing values \n",
    "    all_leaves = [] # Use to store leave\n",
    "    L = 0  #Total number of leaves\n",
    "    Ij = {} # Use to track whether tree rules formed for instances\n",
    "    ranges = []\n",
    "    \n",
    "    for Ai in range(len(M)):\n",
    "        DC_CPY = DC.copy()\n",
    "        index_list = DC_CPY.index\n",
    "        # Generalization Step\n",
    "        min_value = min(DC_CPY[DC_CPY.columns[M[Ai]]])\n",
    "        max_value = max(DC_CPY[DC_CPY.columns[M[Ai]]])\n",
    "        domain_size = max_value - min_value;\n",
    "        #NC = int(math.sqrt(domain_size))\n",
    "        NC = 2\n",
    "        nc1 = NC\n",
    "        min_range = min_value\n",
    "        max_range = min_value + (domain_size / NC)\n",
    "        ranges.append([min_range,max_range])\n",
    "        while NC - 1 != 0:\n",
    "            min_range = max_range\n",
    "            max_range = min_range + domain_size / NC\n",
    "            ranges.append([min_range,max_range])\n",
    "            NC -= 1\n",
    "\n",
    "        DC_CPY['Decision'] = ['' for _ in range(len(DC_CPY))]\n",
    "        for row in range(len(DC_CPY)):      \n",
    "            for rg in ranges:\n",
    "                if  rg[0] <= DC_CPY.iloc[row, M[Ai]] <= rg[1]:\n",
    "                    DC_CPY.iloc[row, len(DC_CPY.columns)-1] = str(rg)\n",
    "                    break\n",
    "\n",
    "        DC_CPY.drop(DC_CPY.columns[M[Ai]], axis=1, inplace=True) #Implementation of Tree\n",
    "        DC_CPY_Temp = DC_CPY.copy()\n",
    "        config = {'algorithm': 'C4.5'} # C4.5\n",
    "        model = chef.fit(DC_CPY, config)\n",
    "        chef.save_model(model, \"model.pkl\")\n",
    "        modelnew = chef.load_model(\"model.pkl\")\n",
    "        leaves_one_missing_col = defaultdict(list)\n",
    "          \n",
    "        for row in range(len(DC_CPY_Temp)):\n",
    "            prediction = chef.predict(modelnew,DC_CPY_Temp.iloc[row,:-1].tolist())\n",
    "        \n",
    "            leaves_one_missing_col[prediction].append(index_list[row])\n",
    "            Ij[prediction] = False\n",
    "            \n",
    "    ######################################Step-3##############################################\n",
    "        DI_temp = DI.drop(DI.columns[M[Ai]], axis=1, inplace=False)\n",
    "        \n",
    "        for row in range(len(DI)):\n",
    "            if pd.isnull(DI.iloc[row, M[Ai]]):\n",
    "                prediction = chef.predict(modelnew,DI_temp.iloc[row].tolist())\n",
    "                leaves_one_missing_col[prediction].append(index_list_DI[row])\n",
    "            \n",
    "        si = len(leaves_one_missing_col.keys())\n",
    "        \n",
    "        L = L + si\n",
    "                \n",
    "        all_leaves.append(leaves_one_missing_col)\n",
    "    print(\"Length of Leaves\",len(all_leaves))\n",
    "    ######################################Step-4##############################################\n",
    "    total = 0\n",
    "    count1 = 0\n",
    "\n",
    "    for tree_leaves in all_leaves:\n",
    "        for key in tree_leaves:\n",
    "            dj_indices = tree_leaves[key]\n",
    "            dj = df_incomplete_data.loc[dj_indices, :]\n",
    "            dj.sort_index(inplace=True)\n",
    "            print(dj.head())\n",
    "            if dj.isnull().sum().sum() != 0:\n",
    "                dj_filled_EMI,itr = impy.em(dj.values)\n",
    "                df_dj_after_EMI=pd.DataFrame(data = dj_filled_EMI, columns=df_incomplete_data.columns, index=dj.index)  \n",
    "                df_incomplete_data = pd.concat([df_incomplete_data , df_dj_after_EMI])\n",
    "                df_incomplete_data = df_incomplete_data.loc[~df_incomplete_data.index.duplicated(keep='last')]  \n",
    "                df_incomplete_data.sort_index(inplace=True)\n",
    "                total += itr\n",
    "            count1 += 1\n",
    "       \n",
    "    return df_incomplete_data, count1, total, nc1;\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53209618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nrms(all_dataset_imputed,df_complete_data):\n",
    "    numvar= len(df_complete_data.columns)\n",
    "    #sum_of_RMSE = 0\n",
    "    sum_of_NRMSE = 0\n",
    "    #sum_of_AE = 0\n",
    "    for i in range(0,numvar):\n",
    "        \n",
    "        l1_after_imputation = all_dataset_imputed.iloc[:,i].values     \n",
    "        l2_complete_data = df_complete_data.iloc[:,i].values     \n",
    "        nrms = nrmsd(l2_complete_data, l1_after_imputation) #Normalized root-mean-square deviation (nRMSD)\n",
    "        sum_of_NRMSE = sum_of_NRMSE + nrms\n",
    "    average_NRMSE_All_Cols = sum_of_NRMSE / numvar\n",
    "    print(average_NRMSE_All_Cols)\n",
    "    return average_NRMSE_All_Cols\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fileName(indexFolder,cFilePath, fileName,count):\n",
    "    summaryName = \"Location of Excel File"\n",
    "    wb = load_workbook(summaryName)\n",
    "    ws1 = wb.active\n",
    "    percentageList = [1,5,10,20]\n",
    "    for j  in percentageList:   \n",
    "        col = cFilePath.columns\n",
    "        incompleteFileName = \"Data_\" + str(indexFolder) + \"_\" + fileName + \"_\" + str(j) + \"%.csv\"\n",
    "        df = pd.read_csv(\"Incomplete File Location"+incompleteFileName, header = None)\n",
    "        df.columns = col\n",
    "        #cFilePath.drop(columns = ['Labels'],axis = 1, inplace = True)\n",
    "        #df.drop(columns = ['Labels'], axis = 1,  inplace = True)\n",
    "        #col1 = cFilePath.columns\n",
    "\n",
    "        start_time = time.time()\n",
    "        all_dataset_imputed, count1, total, nc = DMI(cFilePath , df)\n",
    "        timeFinal = (time.time() - start_time)\n",
    "        all_dataset_imputed.to_csv(\"File Location to Save" + incompleteFileName, columns = col, index = None)\n",
    "\n",
    "        nrmsValue = nrms(all_dataset_imputed,cFilePath)\n",
    "        \n",
    "        print(incompleteFileName + \", Number of Horizontal Partitions: \" + str(count1) + \", EM Total iterations: \" + str(total)  + \", Convergence(%): 10%\")\n",
    "        ws1['A'+str(count)] = incompleteFileName\n",
    "        ws1['B'+str(count)] = nrmsValue\n",
    "        ws1['C'+str(count)] = timeFinal\n",
    "        ws1['D'+str(count)] = count1\n",
    "        ws1['E'+str(count)] = total\n",
    "        ws1['F'+str(count)] = nc\n",
    "        ws1['G'+str(count)] = 0.1\n",
    "        \n",
    "        print(nrmsValue,timeFinal,incompleteFileName + \", Number of Horizontal Partitions: \" + str(count1) + \", EM Total iterations: \" + str(total)  + \", Convergence(%): 10%\")\n",
    "        #ws1['D'+str(count)] = (\"Number of Horizontal Partitions: \" + str(count1) + \", EM iterations: \" + str(total)  + \", Convergence(%): 10%\" + \", NC: \" + str(nc))\n",
    "\n",
    "        count += 1\n",
    "        #print(\"iteration\",itr)\n",
    "\n",
    "\n",
    "        wb.save(summaryName) \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592bb85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    #"folderName = \"Data \" + str(1) \n",
    #"completeFileName = 'Data_' + str(1) + '.csv'\n",
    "cFilePath = pd.read_csv(\"Complete File Path"+completeFileName)\n",
    "df_complete_data=pd.DataFrame(data=cFilePath, columns=cFilePath.columns, index=cFilePath.index)\n",
    "    \n",
    "count = 1\n",
    "count1 = fileName(1,cFilePath, \"AE\", count)\n",
    "count2 = fileName(1,cFilePath, \"AG\", count1)\n",
    "count3 = fileName(1,cFilePath, \"AL\", count2)\n",
    "count4 = fileName(1,cFilePath, \"AN\", count3) \n",
    "count5 = fileName(1,cFilePath, \"AW\", count4)\n",
    "count6 = fileName(1,cFilePath, \"C\", count5)\n",
    "count7 = fileName(1,cFilePath, \"NE\", count6)\n",
    "count8 = fileName(1,cFilePath, \"NG\", count7)\n",
    "count9 = fileName(1,cFilePath, \"NL\", count8)\n",
    "count10 = fileName(1,cFilePath, \"NN\", count9)\n",
    "count11 = fileName(1,cFilePath, \"NW\", count10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
